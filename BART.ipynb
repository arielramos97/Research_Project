{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvIu69xr-B3b",
        "outputId": "f1816056-0b76-4509-b5cc-7234219bee23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (2.12.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (2023.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (1.24.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (12.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: responses<0.19 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (4.30.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: requests in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->transformers) (3.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: evaluate in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (2023.5.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (1.24.3)\n",
            "Requirement already satisfied: responses<0.19 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: xxhash in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (0.15.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: dill in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->evaluate) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge_score in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: bert_score in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: sacrebleu in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: absl-py in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from rouge_score) (1.24.3)\n",
            "Requirement already satisfied: six>=1.14.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (4.30.0)\n",
            "Requirement already satisfied: requests in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (2.27.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (2.0.1)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from bert_score) (23.1)\n",
            "Requirement already satisfied: portalocker in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sacrebleu) (2.7.0)\n",
            "Requirement already satisfied: regex in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: lxml in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sacrebleu) (4.9.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2023.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.12.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from torch>=1.0.0->bert_score) (4.6.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers>=3.0.0->bert_score) (6.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.15.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.13.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (9.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (4.39.4)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from matplotlib->bert_score) (1.4.4)\n",
            "Requirement already satisfied: click in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from nltk->rouge_score) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: pywin32>=226 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from portalocker->sacrebleu) (306)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->bert_score) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->bert_score) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->bert_score) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from requests->bert_score) (2.0.12)\n",
            "Requirement already satisfied: fsspec in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert_score) (2023.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\aramosvela\\documents\\research_project\\research_env\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install evaluate\n",
        "!pip install rouge_score bert_score sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CURL_CA_BUNDLE'] = ''\n",
        "\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hZ9VNl2W-Rum"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, get_polynomial_decay_schedule_with_warmup\n",
        "from datasets import load_dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LZhkY_sq-kxU"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'daily_dialog'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "12b42efcb8744ffaa75bb1966ef6734d",
            "3168ebc3076542508ea24f60f4e24d92",
            "8876a41716ff437f8cf2845118f152b0",
            "142f6bb226c14bc6ac684fd84934daeb",
            "a5ea4db496ff42119dc5fa42ce71eb40",
            "be132f814cfa4e1cb9e17decce168975",
            "b5de407134ec44b78f70e6f7337a94ab",
            "244b4bc6247f41caa0ae1cdf754bbeff",
            "c300a35c14f64870a6254b3de5c2eb79",
            "b389c98c39234f9cb0ec0196801a9a14",
            "de937ceb03fc4993a8dc4b3acf4cd62c"
          ]
        },
        "id": "wH0gBNp4-WS7",
        "outputId": "09ab30a0-f257-4ac2-fef1-63427332ef72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading  daily_dialog\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset daily_dialog (C:/Users/aramosvela/.cache/huggingface/datasets/daily_dialog/default/1.0.0/1d0a58c7f2a4dab5ed9d01dbde8e55e0058e589ab81fce5c2df929ea810eabcd)\n",
            "100%|██████████| 3/3 [00:00<00:00, 132.02it/s]\n"
          ]
        }
      ],
      "source": [
        "if dataset_name == 'daily_dialog':\n",
        "    print('Loading ', dataset_name)\n",
        "    dataset = load_dataset('daily_dialog')\n",
        "    train_dialogues = dataset['train']['dialog']\n",
        "    valid_dialogues = dataset['validation']['dialog']\n",
        "    test_dialogues = dataset['test']['dialog']\n",
        "elif dataset_name == 'empathetic_dialogues':\n",
        "    print('Loading ', dataset_name)\n",
        "    dataset = load_dataset('empathetic_dialogues')\n",
        "    train_dialogues = dataset['train']\n",
        "    valid_dialogues = dataset['validation']\n",
        "    test_dialogues = dataset['test']\n",
        "else:\n",
        "    print('No dataset selected')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "avHL4Rxj-p7i"
      },
      "outputs": [],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "sp1_token = '<sp1>'\n",
        "sp2_token = '<sp2>'\n",
        "# bos_token = '<bos>'\n",
        "# eos_token = '<eos>'\n",
        "max_len = 1024\n",
        "seed = 0\n",
        "gpu = 0\n",
        "\n",
        "#Tokeniser\n",
        "special_tokens = {#'bos_token': bos_token,\n",
        "                'additional_special_tokens': [sp1_token, sp2_token]}\n",
        "\n",
        "eos_token = tokenizer.eos_token\n",
        "num_new_tokens = tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "vocab_size = len(vocab)\n",
        "# bos_id = vocab[bos_token]\n",
        "# eos_id = vocab[eos_token]\n",
        "sp1_id = vocab[sp1_token]\n",
        "sp2_id = vocab[sp2_token]\n",
        "\n",
        "lr = 2e-5\n",
        "batch_size = 8\n",
        "num_workers = 0\n",
        "num_epochs = 8\n",
        "warmup_ratio = 0.1\n",
        "last_epoch = 0\n",
        "end_command = 'Quit!'\n",
        "top_p = 0.8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab['<pad>']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A subdirectory or file 'saved_models' already exists.\n"
          ]
        }
      ],
      "source": [
        "!mkdir 'saved_models'\n",
        "ckpt_dir = 'saved_models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "omRibsHe-sU7"
      },
      "outputs": [],
      "source": [
        "def preprocess_dialog(dialog, window_size=5):\n",
        "    instances = []\n",
        "    \n",
        "    # response = dialog[\"dialog\"][-1]  # Last utterance as the response\n",
        "\n",
        "    for i in range(0, len(dialog) - window_size - 1, 2):\n",
        "        \n",
        "        window = dialog[i:i+window_size]\n",
        "        window_context = []\n",
        "        for j, utterance in enumerate(window):\n",
        "            speaker = sp1_token if j % 2 == 0 else sp2_token\n",
        "            window_context.append(speaker + \" \" + utterance)\n",
        "\n",
        "        # Add special tokens for bos, eos\n",
        "        window_context.insert(0, '<s>')\n",
        "        # window_context.append(\"</s>\")\n",
        "\n",
        "        window_context = ' '.join(window_context)\n",
        "        window_context = window_context + sp2_token\n",
        "        response =  dialog[i+window_size] + '</s>'\n",
        "\n",
        "        # print('window_context: ', type(window_context), window_context)\n",
        "        # print('response: ', type(response), response)\n",
        "        \n",
        "\n",
        "\n",
        "        # print()\n",
        "        # print('window_context: ', window_context)\n",
        "        # print('response: ', response)\n",
        "\n",
        "\n",
        "        # Tokenize the context and response\n",
        "        input_ids = tokenizer.encode_plus(window_context, add_special_tokens=False, padding='max_length', max_length=512, truncation=True , return_tensors=\"pt\")\n",
        "\n",
        "        decoder_input_ids = tokenizer.encode_plus(response, add_special_tokens=False, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        labels = decoder_input_ids['input_ids']\n",
        "\n",
        "        labels[labels[:, :] == vocab['<pad>']] = -100\n",
        "\n",
        "        instance = {\n",
        "            \"input_ids\": input_ids[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": input_ids[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": labels.squeeze(0)\n",
        "            # \"decoder_input_ids\": decoder_input_ids[\"input_ids\"].squeeze(0),\n",
        "            # \"decoder_attention_mask\": decoder_input_ids[\"attention_mask\"].squeeze(0)\n",
        "            \n",
        "        }\n",
        "\n",
        "        # print('input_ids: ', instance['input_ids'].shape)\n",
        "        # print('attention_mask: ', instance['attention_mask'].shape)\n",
        "        # print('decoder_input_ids: ', instance['decoder_input_ids'].shape)\n",
        "        # print('decoder_attention_mask: ', instance['decoder_attention_mask'].shape)\n",
        "        instances.append(instance)\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    return instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwBhFj9RAaA1",
        "outputId": "efab1dd7-d942-40b8-9d0c-166e0daaa07f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Say , Jim , how about going for a few beers after dinner ? ',\n",
              " ' You know that is tempting but is really not good for our fitness . ',\n",
              " ' What do you mean ? It will help us to relax . ',\n",
              " \" Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ? \",\n",
              " \" I guess you are right.But what shall we do ? I don't feel like sitting at home . \",\n",
              " ' I suggest a walk over to the gym where we can play singsong and meet some of our friends . ',\n",
              " \" That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them . \",\n",
              " ' Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too . ',\n",
              " \" Good.Let ' s go now . \",\n",
              " ' All right . ']"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dialogues[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VGzaUqe_45y",
        "outputId": "e1cc6ef8-4058-4f58-edb9-0a4a8747cc8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11118/11118 [00:13<00:00, 839.65it/s]\n",
            "100%|██████████| 1000/1000 [00:01<00:00, 805.37it/s]\n",
            "100%|██████████| 1000/1000 [00:01<00:00, 853.29it/s]\n"
          ]
        }
      ],
      "source": [
        "train_instances = []\n",
        "val_instances = []\n",
        "\n",
        "#dummy\n",
        "test_instances = []\n",
        "\n",
        "for dialog in tqdm(train_dialogues):\n",
        "    train_instances.extend(preprocess_dialog(dialog))\n",
        "    # break\n",
        "\n",
        "for dialog in tqdm(valid_dialogues):\n",
        "    val_instances.extend(preprocess_dialog(dialog))\n",
        "\n",
        "for dialog in tqdm(test_dialogues):\n",
        "    test_instances.extend(preprocess_dialog(dialog))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([    0, 50265, 34673,  2156,  2488,  2156,   141,    59,   164,    13,\n",
              "           10,   367, 16328,    71,  3630, 17487, 50266,  1185,   216,    14,\n",
              "           16, 25057,    53,    16,   269,    45,   205,    13,    84,  5704,\n",
              "          479, 50265,  2264,   109,    47,  1266, 17487,    85,    40,   244,\n",
              "          201,     7, 12327,   479, 50266,  8275,    47,   269,   206,    98,\n",
              "        17487,    38,   218,    75,   479,    85,    40,    95,   146,   201,\n",
              "         5886,     8,  1760, 15470,   479,  9427,    94,    86, 17487, 50265,\n",
              "          100,  4443,    47,    32,   235,     4,  1708,    99,  5658,    52,\n",
              "          109, 17487,    38,   218,    75,   619,   101,  2828,    23,   184,\n",
              "          479, 50266,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
              "            1,     1])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_instances[0]['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([   38,  3608,    10,  1656,    81,     7,     5,  6545,   147,    52,\n",
              "           64,   310, 22707,  1657,     8,   972,   103,     9,    84,   964,\n",
              "          479,  1437,     2,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
              "         -100,  -100])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_instances[0]['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' I suggest a walk over to the gym where we can play singsong and meet some of our friends . '"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# tokenizer.decode(train_instances[0]['decoder_input_ids'], skip_special_tokens=True , clean_up_tokenization_spaces=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "CWIx5_pxF7ub"
      },
      "outputs": [],
      "source": [
        "class DialogueDataset(Dataset):\n",
        "    def __init__(self, instances):\n",
        "        self.instances = instances\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.instances)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.instances[idx]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "22UeCWIWGDQ_"
      },
      "outputs": [],
      "source": [
        "#Create data loaders\n",
        "train_dataset = DialogueDataset(train_instances)\n",
        "val_dataset = DialogueDataset(val_instances)\n",
        "test_dataset =  DialogueDataset(test_instances)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9UaJ_vkH41R",
        "outputId": "93e50bd2-fc72-4564-bf11-f027381b97cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset.__getitem__(0)['input_ids'].shape)\n",
        "print(train_dataset.__getitem__(0)['attention_mask'].shape)\n",
        "\n",
        "# print(train_dataset.__getitem__(0)['decoder_input_ids'].shape)\n",
        "# print(train_dataset.__getitem__(0)['decoder_attention_mask'].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_bjX0MSI8Nz",
        "outputId": "a4b91b66-6d2d-41b8-bd28-3a8e74676a80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512])\n",
            "torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset.__getitem__(1)['input_ids'].shape)\n",
        "print(train_dataset.__getitem__(1)['attention_mask'].shape)\n",
        "\n",
        "# print(train_dataset.__getitem__(1)['decoder_input_ids'].shape)\n",
        "# print(train_dataset.__getitem__(1)['decoder_attention_mask'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fvv6sOcPGjiH"
      },
      "outputs": [],
      "source": [
        "def fix_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NutyRZITGnjZ",
        "outputId": "b9234e54-5bfc-4eaf-bff4-52e8b269ee40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(f\"cuda:{gpu}\")\n",
        "    print('Using GPU')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('Using CPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICRf4uw3-6eJ",
        "outputId": "709314ac-454a-4e8e-b9d7-9c7f191e153b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50267, 768)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Define the BART model and optimizer\n",
        "\n",
        "fix_seed(seed)\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\").to(device)\n",
        "model.resize_token_embeddings(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9izc56rG5UI",
        "outputId": "2d48b0a6-a907-42f1-df68-7c441316ca05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading the optimizer...\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading the optimizer...\")\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrS-ZOTaluhD",
        "outputId": "f9e46c34-6ac4-4e08-90b9-c4e4ffdb3a29"
      },
      "outputs": [],
      "source": [
        "# Calculate total training steps\n",
        "num_batches = len(test_dataloader) #len(train_dataloader) ###CHANGE LATER\n",
        "total_train_steps = num_epochs * num_batches\n",
        "warmup_steps = int(warmup_ratio * total_train_steps)\n",
        "\n",
        "sched = get_polynomial_decay_schedule_with_warmup(\n",
        "    optim,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=total_train_steps,\n",
        "    power=2\n",
        ")\n",
        "\n",
        "writer = SummaryWriter()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validation():\n",
        "\n",
        "    print(\"Validation processing...\")\n",
        "    model.eval()\n",
        "            \n",
        "    valid_losses = []\n",
        "    valid_ppls = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(test_dataloader)):\n",
        "            \n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            # decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
        "            # decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
        "            \n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                # decoder_input_ids=decoder_input_ids,\n",
        "                # decoder_attention_mask=decoder_attention_mask,\n",
        "                labels = labels\n",
        "                # use_cache=False\n",
        "            )\n",
        "            \n",
        "            loss = outputs.loss\n",
        "            \n",
        "            valid_losses.append(loss.detach())\n",
        "            ppl = torch.exp(loss.detach())\n",
        "            valid_ppls.append(ppl)\n",
        "        \n",
        "        valid_losses = [loss.item() for loss in valid_losses]\n",
        "        valid_ppls = [ppl.item() if not math.isinf(ppl.item()) else 1e+8 for ppl in valid_ppls]\n",
        "        valid_loss = np.mean(valid_losses)\n",
        "        valid_ppl = np.mean(valid_ppls)\n",
        "        \n",
        "        if math.isnan(valid_ppl):\n",
        "            valid_ppl = 1e+8\n",
        "            \n",
        "    return valid_loss, valid_ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux0Qm015GU_4",
        "outputId": "606cf976-167b-45b2-93c7-aea400239997"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "\n",
        "    fix_seed(seed)  # Fix seed before training\n",
        "    print(\"Training starts.\")\n",
        "\n",
        "    best_loss = sys.float_info.max\n",
        "    last_epoch= 0\n",
        "\n",
        "    start_epoch = last_epoch +1\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch+num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        print(f\"#\"*50 + f\"Epoch: {epoch}\" + \"#\"*50)\n",
        "        train_losses = []\n",
        "        train_ppls = []\n",
        "\n",
        "        # total_loss = 0\n",
        "\n",
        "        for batch in tqdm(val_dataloader):\n",
        "\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "            # decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\n",
        "            # decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\n",
        "\n",
        "            optim.zero_grad()\n",
        "\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                # decoder_input_ids=decoder_input_ids,\n",
        "                # decoder_attention_mask=decoder_attention_mask,\n",
        "                labels = labels\n",
        "                # use_cache=False\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            sched.step()\n",
        "\n",
        "            train_losses.append(loss.detach())\n",
        "            ppl = torch.exp(loss.detach())\n",
        "            train_ppls.append(ppl)\n",
        "        \n",
        "        train_losses = [loss.item() for loss in train_losses]\n",
        "        train_ppls = [ppl.item() if not math.isinf(ppl.item()) else 1e+8 for ppl in train_ppls]\n",
        "        train_loss = np.mean(train_losses)\n",
        "        train_ppl = np.mean(train_ppls)\n",
        "        print(f\"Train loss: {train_loss} || Train perplexity: {train_ppl}\")\n",
        "\n",
        "        writer.add_scalar(\"Loss/train\", train_loss, epoch)\n",
        "        writer.add_scalar(\"PPL/train\", train_ppl, epoch)\n",
        "        \n",
        "        last_epoch += 1\n",
        "        \n",
        "        valid_loss, valid_ppl = validation()\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            state_dict = {\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optim_state_dict': optim.state_dict(),\n",
        "                'sched_state_dict': sched.state_dict(),\n",
        "                'loss': best_loss,\n",
        "                'epoch': last_epoch\n",
        "            }\n",
        "            \n",
        "            torch.save(state_dict, f\"{ckpt_dir}/best_ckpt_epoch={epoch}_valid_loss={round(best_loss, 4)}.ckpt\")\n",
        "            print(\"*\"*10 + \"Current best checkpoint is saved.\" + \"*\"*10)\n",
        "            print(f\"{ckpt_dir}/best_ckpt_epoch={epoch}_valid_loss={round(best_loss, 4)}.ckpt\")\n",
        "            \n",
        "        print(f\"Best valid loss: {best_loss}\")\n",
        "        print(f\"Valid loss: {valid_loss} || Valid perplexity: {valid_ppl}\")\n",
        "        \n",
        "        writer.add_scalar(\"Loss/valid\", valid_loss, epoch)\n",
        "        writer.add_scalar(\"PPL/valid\", valid_ppl, epoch)\n",
        "        \n",
        "        writer.add_scalars(\"Losses\", {\n",
        "            'train': train_loss, \n",
        "            'valid': valid_loss,\n",
        "        }, epoch)\n",
        "        writer.add_scalars(\"PPLs\", {\n",
        "            'train': train_ppl,\n",
        "            'valid': valid_ppl,\n",
        "        }, epoch)\n",
        "            \n",
        "    print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training starts.\n",
            "##################################################Epoch: 1##################################################\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 10/184 [03:20<58:05, 20.03s/it] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train()\n",
            "Cell \u001b[1;32mIn[71], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m# decoder_input_ids = batch[\"decoder_input_ids\"].to(device)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# decoder_attention_mask = batch[\"decoder_attention_mask\"].to(device)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m optim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 31\u001b[0m outputs \u001b[39m=\u001b[39m model(\n\u001b[0;32m     32\u001b[0m     input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m     33\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m     34\u001b[0m     \u001b[39m# decoder_input_ids=decoder_input_ids,\u001b[39;49;00m\n\u001b[0;32m     35\u001b[0m     \u001b[39m# decoder_attention_mask=decoder_attention_mask,\u001b[39;49;00m\n\u001b[0;32m     36\u001b[0m     labels \u001b[39m=\u001b[39;49m labels\n\u001b[0;32m     37\u001b[0m     \u001b[39m# use_cache=False\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m loss \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mloss\n\u001b[0;32m     41\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1379\u001b[0m, in \u001b[0;36mBartForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[39mif\u001b[39;00m decoder_input_ids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m decoder_inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m         decoder_input_ids \u001b[39m=\u001b[39m shift_tokens_right(\n\u001b[0;32m   1376\u001b[0m             labels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mpad_token_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id\n\u001b[0;32m   1377\u001b[0m         )\n\u001b[1;32m-> 1379\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(\n\u001b[0;32m   1380\u001b[0m     input_ids,\n\u001b[0;32m   1381\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1382\u001b[0m     decoder_input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1383\u001b[0m     encoder_outputs\u001b[39m=\u001b[39;49mencoder_outputs,\n\u001b[0;32m   1384\u001b[0m     decoder_attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1385\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1386\u001b[0m     decoder_head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1387\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1388\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1389\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1390\u001b[0m     decoder_inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1391\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1392\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1393\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1394\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1395\u001b[0m )\n\u001b[0;32m   1397\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(outputs[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1398\u001b[0m lm_logits \u001b[39m=\u001b[39m lm_logits \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_logits_bias\u001b[39m.\u001b[39mto(lm_logits\u001b[39m.\u001b[39mdevice)\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:1243\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1240\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m   1242\u001b[0m \u001b[39mif\u001b[39;00m encoder_outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1243\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[0;32m   1244\u001b[0m         input_ids\u001b[39m=\u001b[39;49minput_ids,\n\u001b[0;32m   1245\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1246\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[0;32m   1247\u001b[0m         inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[0;32m   1248\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1249\u001b[0m         output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1250\u001b[0m         return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1251\u001b[0m     )\n\u001b[0;32m   1252\u001b[0m \u001b[39m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[0;32m   1253\u001b[0m \u001b[39melif\u001b[39;00m return_dict \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:859\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    852\u001b[0m         layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[0;32m    853\u001b[0m             create_custom_forward(encoder_layer),\n\u001b[0;32m    854\u001b[0m             hidden_states,\n\u001b[0;32m    855\u001b[0m             attention_mask,\n\u001b[0;32m    856\u001b[0m             (head_mask[idx] \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m    857\u001b[0m         )\n\u001b[0;32m    858\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 859\u001b[0m         layer_outputs \u001b[39m=\u001b[39m encoder_layer(\n\u001b[0;32m    860\u001b[0m             hidden_states,\n\u001b[0;32m    861\u001b[0m             attention_mask,\n\u001b[0;32m    862\u001b[0m             layer_head_mask\u001b[39m=\u001b[39;49m(head_mask[idx] \u001b[39mif\u001b[39;49;00m head_mask \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    863\u001b[0m             output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    864\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:333\u001b[0m, in \u001b[0;36mBartEncoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[39m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(seq_len, batch, embed_dim)`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m        returned tensors for more detail.\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    332\u001b[0m residual \u001b[39m=\u001b[39m hidden_states\n\u001b[1;32m--> 333\u001b[0m hidden_states, attn_weights, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[0;32m    334\u001b[0m     hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m    335\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    336\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    337\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    338\u001b[0m )\n\u001b[0;32m    339\u001b[0m hidden_states \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdropout(hidden_states, p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m    340\u001b[0m hidden_states \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m hidden_states\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:254\u001b[0m, in \u001b[0;36mBartAttention.forward\u001b[1;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    251\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len) \u001b[39m+\u001b[39m attention_mask\n\u001b[0;32m    252\u001b[0m     attn_weights \u001b[39m=\u001b[39m attn_weights\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads, tgt_len, src_len)\n\u001b[1;32m--> 254\u001b[0m attn_weights \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49msoftmax(attn_weights, dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m layer_head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     \u001b[39mif\u001b[39;00m layer_head_mask\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,):\n",
            "File \u001b[1;32mc:\\Users\\aramosvela\\Documents\\Research_Project\\research_env\\lib\\site-packages\\torch\\nn\\functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49msoftmax(dim)\n\u001b[0;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs=1\n",
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer(window_size=5):\n",
        "    model.eval()\n",
        "    fix_seed(seed)\n",
        "\n",
        "    generated_responses = []\n",
        "    actual_responses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for i, batch in enumerate(tqdm(test_dialogues)):\n",
        "\n",
        "            for i in range(len(batch) - window_size - 1):\n",
        "                \n",
        "                window = dialog[i:i+window_size]\n",
        "                window_context = []\n",
        "                for j, utterance in enumerate(window):\n",
        "                    speaker = sp1_token if j % 2 == 0 else sp2_token\n",
        "                    window_context.append(speaker + \" \" + utterance)\n",
        "\n",
        "                # Add special tokens for bos, eos\n",
        "                window_context.insert(0, '<s>')\n",
        "                # window_context.append(\"</s>\")\n",
        "\n",
        "                window_context = ' '.join(window_context)\n",
        "                window_context = window_context + sp2_token\n",
        "\n",
        "                print('window context: ', window_context)\n",
        "\n",
        "                #Get encodings\n",
        "                encodings = tokenizer.encode_plus(window_context, add_special_tokens=False, padding='max_length', max_length=512, truncation=True , return_tensors=\"pt\")\n",
        "                \n",
        "                input_ids = encodings['input_ids']\n",
        "                attention_mask = encodings['attention_mask']\n",
        "\n",
        "                print('input_ids: ', input_ids.shape, input_ids)\n",
        "                print('attention_mask: ', attention_mask.shape, attention_mask)\n",
        "\n",
        "                output_ids = model.generate(input_ids, max_length=512, do_sample=True, top_p=top_p).squeeze(0)\n",
        "\n",
        "                #Generate response\n",
        "                # output_ids = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                print('encoded response: ', output_ids)\n",
        "                # print('encoded response: ', output_ids.squeeze(0))\n",
        "\n",
        "                response = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "\n",
        "                print('generated response: ', response)\n",
        "\n",
        "                actual_response = dialog[i+window_size]\n",
        "\n",
        "                print('actual_response: ', actual_response)\n",
        "\n",
        "                generated_responses.append(response)\n",
        "                actual_responses.append(actual_response)\n",
        "\n",
        "                break\n",
        "            break\n",
        "\n",
        "def nucleus_sampling(input_ids, attention_mask): #token_type_ids, input_len, next_sp_id):\n",
        "\n",
        "    output_ids = []\n",
        "    for pos in range(len(input_ids), max_len):\n",
        "\n",
        "        # output = model(input_ids=input_ids, attention_mask=attention_mask)[0][:, pos-1] \n",
        "        # print('debug: ', output[0])\n",
        "        # break\n",
        "        output = model(input_ids=input_ids, attention_mask=attention_mask)[0][:, pos-1]  # (1, V)\n",
        "        output = F.softmax(output, dim=-1)  # (1, V)\n",
        "\n",
        "    \n",
        "        \n",
        "        sorted_probs, sorted_idxs = torch.sort(output, descending=True)\n",
        "        cumsum_probs = torch.cumsum(sorted_probs, dim=-1)  # (1, V)\n",
        "        idx_remove = cumsum_probs > top_p\n",
        "        idx_remove[:, 1:] = idx_remove[:, :-1].clone()\n",
        "        idx_remove[:, 0] = False\n",
        "        sorted_probs[idx_remove] = 0.0\n",
        "        sorted_probs /= torch.sum(sorted_probs, dim=-1, keepdim=True)  # (1, V)\n",
        "        \n",
        "        probs = torch.zeros(output.shape, device=device).scatter_(-1, sorted_idxs, sorted_probs)  # (1, V)\n",
        "        idx = torch.multinomial(probs, 1)  # (1, 1)\n",
        "        \n",
        "        idx_item = idx.squeeze(-1).squeeze(-1).item()\n",
        "        output_ids.append(idx_item)\n",
        "\n",
        "        print('xd')\n",
        "        \n",
        "        if idx_item == vocab['</s>']:\n",
        "            break\n",
        "            \n",
        "        # input_ids = torch.cat((input_ids, idx), dim=-1)\n",
        "\n",
        "        # next_type_id = torch.LongTensor([[next_sp_id]]).to(device)\n",
        "        # token_type_ids = torch.cat((token_type_ids, next_type_id), dim=-1)\n",
        "        # assert input_ids.shape == token_type_ids.shape\n",
        "        \n",
        "    return output_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "window context:  <s> <sp1> What a nice day !  <sp2>  yes . How about going out and enjoying the sunshine on the grass ?  <sp1>  great , let's go !  <sp2>  hey , darling , I think I might have a little heatstroke from being in the sun all day . I was so relaxed . It felt as if I were in another world .  <sp1>  exactly . You know , the sunshine and wind remind me of our honeymoon . You remember ? The island , the sound of the waves , the salty sea air and the sunshine ... <sp2>\n",
            "input_ids:  torch.Size([1, 512]) tensor([[    0, 50265,  2264,    10,  2579,   183, 27785, 50266, 10932,   479,\n",
            "          1336,    59,   164,    66,     8,  6218,     5, 15049,    15,     5,\n",
            "          6964, 17487, 50265, 12338,  2156,   905,    18,   213, 27785, 50266,\n",
            "         12229,  2156, 30213,  2156,    38,   206,    38,   429,    33,    10,\n",
            "           410,  2859, 17097,    31,   145,    11,     5,  3778,    70,   183,\n",
            "           479,    38,    21,    98, 11956,   479,    85,  1299,    25,   114,\n",
            "            38,    58,    11,   277,   232,   479, 50265,  3463, 45548,   479,\n",
            "           370,   216,  2156,     5, 15049,     8,  2508,  8736,   162,     9,\n",
            "            84, 10658, 16956,   479,   370,  2145, 17487,    20,  2946,  2156,\n",
            "             5,  2369,     9,     5,  6995,  2156,     5, 31924,  3342,   935,\n",
            "             8,     5, 15049,  1666, 50266,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1]])\n",
            "attention_mask:  torch.Size([1, 512]) tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000 [00:02<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded response:  tensor([    2,     0,  1437,  2264,    10,  2579,   183, 27785,  1437,  1437,\n",
            "         1437,    38,   206,    38,   429,    33,    10,   410,  2859, 17097,\n",
            "           31,   145,    11,     5,  3778,    70,   183,   479,  1437,  1437,\n",
            "          653,    10,  9869,   183, 27785, 17487,  1437,  1437,     2])\n",
            "generated response:   What a nice day!    I think I might have a little heatstroke from being in the sun all day.   What a lovely day!?  \n",
            "actual_response:   yes , it was wonderful but it's already been a year . How time flies ! \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "infer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "B7xAWdioqKtX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Response: How are you? I'm doing well. How about you? Me too. I'm good too. Thanks for asking.\n"
          ]
        }
      ],
      "source": [
        "def generate_response(context):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(context, padding='max_length', max_length=512, truncation=True , return_tensors=\"pt\").to(device)\n",
        "    output_ids = model.generate(input_ids=input_ids, max_length=512, )\n",
        "    response = tokenizer.decode(output_ids.squeeze(), skip_special_tokens=True)\n",
        "\n",
        "    return response\n",
        "\n",
        "context = \"<sp1> How are you? <sp2> I'm doing well. How about you? <sp1> I'm good too. Thanks for asking. <sp2>\"\n",
        "\n",
        "response = generate_response(context)\n",
        "print(\"Generated Response:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkrBu0oBSWqk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12b42efcb8744ffaa75bb1966ef6734d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3168ebc3076542508ea24f60f4e24d92",
              "IPY_MODEL_8876a41716ff437f8cf2845118f152b0",
              "IPY_MODEL_142f6bb226c14bc6ac684fd84934daeb"
            ],
            "layout": "IPY_MODEL_a5ea4db496ff42119dc5fa42ce71eb40"
          }
        },
        "142f6bb226c14bc6ac684fd84934daeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b389c98c39234f9cb0ec0196801a9a14",
            "placeholder": "​",
            "style": "IPY_MODEL_de937ceb03fc4993a8dc4b3acf4cd62c",
            "value": " 3/3 [00:00&lt;00:00, 150.89it/s]"
          }
        },
        "244b4bc6247f41caa0ae1cdf754bbeff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3168ebc3076542508ea24f60f4e24d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be132f814cfa4e1cb9e17decce168975",
            "placeholder": "​",
            "style": "IPY_MODEL_b5de407134ec44b78f70e6f7337a94ab",
            "value": "100%"
          }
        },
        "8876a41716ff437f8cf2845118f152b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_244b4bc6247f41caa0ae1cdf754bbeff",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c300a35c14f64870a6254b3de5c2eb79",
            "value": 3
          }
        },
        "a5ea4db496ff42119dc5fa42ce71eb40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b389c98c39234f9cb0ec0196801a9a14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5de407134ec44b78f70e6f7337a94ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be132f814cfa4e1cb9e17decce168975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c300a35c14f64870a6254b3de5c2eb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de937ceb03fc4993a8dc4b3acf4cd62c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
